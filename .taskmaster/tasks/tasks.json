{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "Implement Lexer and Parser for Medi Language",
        "description": "Develop a recursive descent parser for Medi's core syntax with support for healthcare-specific constructs and AST generation.",
        "details": "Create a lexer that handles UTF-8 source encoding and tokenizes Medi code with support for medical literals. Implement a recursive descent parser that can parse the core syntax including healthcare-specific constructs like `fhir_query`, `predict_risk`, and `regulate`. Generate an Abstract Syntax Tree (AST) with healthcare-aware semantic analysis. Implement clinician-friendly error reporting.\n\nPseudo-code for parser implementation:\n```rust\nstruct Token { type: TokenType, value: String, position: Position }\nstruct AST { type: NodeType, children: Vec<AST>, value: Option<Value> }\n\nfn tokenize(source: String) -> Vec<Token> {\n  // Implement lexical analysis for Medi tokens\n  // Handle medical literals and healthcare-specific keywords\n}\n\nfn parse(tokens: Vec<Token>) -> Result<AST, ParseError> {\n  // Implement recursive descent parser\n  // Handle healthcare constructs like fhir_query, regulate, etc.\n  // Build and return AST\n}\n\nfn report_error(error: ParseError) -> String {\n  // Generate clinician-friendly error messages\n}\n```",
        "testStrategy": "Create unit tests for lexer and parser components. Test with valid and invalid Medi code samples, including all healthcare-specific constructs from the PRD examples. Verify correct AST generation for each language construct. Test error reporting with various syntax errors to ensure messages are clear and clinician-friendly.",
        "priority": "high",
        "dependencies": [],
        "status": "done",
        "subtasks": [
          {
            "id": 1,
            "title": "Define Token Types and Structure",
            "description": "Define all v0.1 token types per LANG_SPEC.md, including exact keyword and operator/delimiter sets, literals, and identifiers. Ensure a UTF-8-aware token structure with precise position tracking.",
            "dependencies": [],
            "details": "Acceptance Criteria:\n- Enumerate v0.1 Keywords exactly as in LANG_SPEC.md:\n  module import fn let const type struct enum trait impl pub priv return while for in match if else loop break continue true false nil fhir_query regulate federated scope real_time\n- Enumerate v0.1 Operators & Delimiters exactly as in LANG_SPEC.md:\n  + - * / % = == != < > <= >= += -= *= /= %= && || ! -> => { } ( ) [ ] . :: , : ; @ # ? .. ..= ...\n- Identifier rules: start with letter/underscore; followed by letters/digits/underscores; case-sensitive; cannot use reserved keywords\n- Literals supported: integers, floats, strings (including multiline), booleans, datetime, and medical literals (e.g., pid(\"PT123\"), icd10(\"A00.0\"))\n- Healthcare keywords present as tokens: fhir_query, regulate, federated, scope, real_time\n- Pipeline operator (|>) is NOT part of v0.1 and must not be emitted as a single token\n- Token structure fields and semantics:\n  - token_type (enum covering all above)\n  - lexeme (interned or owned string)\n  - location with line (1-based), column (1-based), offset (0-based byte index)\n  - Column advancement and end-column helpers use Unicode scalar count (chars), not bytes; grapheme-cluster precision may be added later\n- Unit tests:\n  - Verify exact line/column/offset for single-line ASCII tokens\n  - Verify multi-line and UTF-8 inputs (e.g., emojis, accented chars) maintain correct positions\n  - Cover all listed keywords and a representative sample of operators/delimiters including :: and ..=\n- Documentation: brief purpose for each token category and any healthcare-specific semantics\nEstimated Complexity: Medium - requires careful alignment with the spec and Unicode-aware position tracking.",
            "status": "done"
          },
          {
            "id": 2,
            "title": "Implement Lexical Analyzer (Lexer)",
            "description": "Develop the lexer component that converts input text into a stream of tokens based on the defined token types. Ensure proper handling of whitespace, comments, and special characters.",
            "dependencies": [
              1
            ],
            "details": "Acceptance Criteria:\n- Correctly tokenize all v0.1 language constructs per `LANG_SPEC.md`, including healthcare keywords and medical literals (e.g., pid(\"PT123\"), icd10(\"A00.0\")).\n- UTF-8 input handling and platform-independent line endings (CRLF/CR/LF) with consistent normalization.\n- Handle whitespace and comments per `LANG_SPEC.md` (single-line and block forms as specified).\n- Unicode-aware position tracking (line 1-based, column 1-based using Unicode scalar count, not bytes); verified on multi-line and non-ASCII input.\n- Support string literals with escape sequences and multiline strings as specified.\n- Standardized lexer error token: emit TokenType::Error(\"Invalid token '<lexeme>'\") for invalid input; keep debug logging behind a `logging` feature (no behavior change when disabled).\n- Large-input performance: provide streaming/chunked lexing path with bounded memory and stable throughput; avoid loading entire files into memory.\n- Do not emit pipeline `|>` as a single token (ensure it lexes according to v0.1 rules).\n- Comprehensive tests:\n  - All healthcare keywords and representative medical literals.\n  - Unicode and cross-platform line endings.\n  - Edge cases: unterminated strings/comments, invalid escapes, extremely long tokens.\n  - PRD key examples compile through lexing without lexer errors.\n- Contribute to PRD compile-time target by ensuring lexing is not the bottleneck for simple scripts (< 2s end-to-end).\nEstimated Complexity: High - requires careful state management and performance considerations.",
            "status": "done"
          },
          {
            "id": 3,
            "title": "Implement Recursive Descent Parser",
            "description": "Build the parser that consumes tokens from the lexer and verifies syntactic correctness according to the grammar rules. Implement recursive descent parsing techniques for healthcare-specific constructs.",
            "dependencies": [
              1,
              2
            ],
            "details": "Acceptance Criteria:\n- Implementation of all grammar rules\n- Proper handling of operator precedence\n- Support for nested expressions and statements\n- Memory-efficient parsing of large documents\n- Comprehensive test suite for all grammar constructs\n- Documentation of parsing algorithms\nEstimated Complexity: Very High - requires implementation of mutually recursive procedures and careful handling of grammar ambiguities.",
            "status": "done"
          },
          {
            "id": 4,
            "title": "Develop Abstract Syntax Tree (AST) Generation",
            "description": "Extend the parser to generate an Abstract Syntax Tree representation of the parsed input, which will be used for further processing and evaluation.",
            "dependencies": [
              3
            ],
            "details": "Acceptance Criteria:\n- Well-defined AST node types for all language constructs\n- Visitor pattern implementation for AST traversal\n- Position information preserved in AST nodes\n- Memory-efficient AST representation\n- Serialization/deserialization support\n- Unit tests for AST generation and traversal\nEstimated Complexity: High - requires careful design of node types and efficient memory management.",
            "status": "done"
          },
          {
            "id": 5,
            "title": "Implement Clinician-Friendly Error Reporting",
            "description": "Create a robust error reporting system that provides clear, contextual error messages suitable for clinicians without programming background. Include suggestions for fixing common errors.",
            "dependencies": [
              2,
              3,
              4
            ],
            "details": "Acceptance Criteria:\n- Clear error messages with line and column information\n- Context-aware error suggestions\n- Categorization of errors by severity\n- Recovery mechanisms to continue parsing after errors\n- Visual highlighting of error locations in source\n- Documentation of common errors and solutions\n- User testing with clinical staff\nEstimated Complexity: High - requires natural language generation and deep understanding of common user mistakes.",
            "status": "done"
          },
          {
            "id": 6,
            "title": "Plan pipeline operator lexer design (no behavior change in v0.1)",
            "description": "Design the approach for optional single-token pipeline operator '|>' recognition across lexers without changing v0.1 behavior by default.\\n\\nScope:\\n- Define feature flag name (e.g., 'pipeline_op') in compiler/medic_lexer/Cargo.toml; disabled by default.\\n- Add planned variants: LogosToken::PipeGreater and TokenType::PipeGreater (gated usage).\\n- Plan updates to convert_logos_to_token() to map PipeGreater when feature enabled.\\n- Plan recognition paths in lexers: lexer/mod.rs, streaming_lexer.rs, chunked_lexer.rs, including chunk-boundary handling.\\n- Ensure position tracking and performance unchanged.\\n\\nTests to plan:\\n- Default (no feature): '|>' tokenizes as BitOr, Greater in all lexers (keep existing tests).\\n- With feature: '|>' tokenizes as single PipeGreater in all lexers, including across chunk boundaries.\\n- Conversion mapping and Location correctness.\\n\\nDocs to plan:\\n- Update LANG_SPEC.md to document the operator and feature gating.\\n- Note backward compatibility and default-off behavior.\\n\\nAcceptance Notes:\\n- This subtask is planning-only; no behavior change for v0.1.\\n- Output: a brief design note and checklist to implement in the follow-up task.",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 1
          }
        ]
      },
      {
        "id": 2,
        "title": "Develop Healthcare-Specific Type System",
        "description": "Implement a type system with healthcare data types, type checking for healthcare operations, and type inference.",
        "details": "Design and implement a type system that includes basic types (int, float, string, bool) and healthcare-specific types like `FHIRPatient`, `Observation`, etc. Implement type checking for healthcare-specific operations and type inference for improved developer experience. Add safety guarantees for patient data handling.\n\nThe type system should include:\n1. Core medical types: patient_id, vital, lab_result\n2. Simple trait system with MedicalRecord, PrivacyProtected traits\n3. Type inference for local variables\n\nPseudo-code for type system:\n```rust\nenum Type {\n  Int, Float, String, Bool,\n  PatientId, Vital, LabResult,\n  FHIRPatient, Observation,\n  // Other healthcare types\n}\n\ntrait MedicalRecord { /* ... */ }\ntrait PrivacyProtected { /* ... */ }\n\nfn infer_type(ast_node: &AST, context: &TypeContext) -> Result<Type, TypeError> {\n  // Implement type inference logic\n}\n\nfn check_types(ast: &AST) -> Result<(), TypeError> {\n  // Implement type checking for the entire AST\n  // Special handling for healthcare operations\n}\n```",
        "testStrategy": "Create unit tests for type checking and inference. Test with various healthcare data types and operations. Verify type safety for patient data handling. Test edge cases like type conversions and inference in complex expressions. Ensure type errors are reported with clear, healthcare-context-aware messages.",
        "priority": "high",
        "dependencies": [
          1
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Basic Type System Implementation",
            "description": "Implement the core type system infrastructure including primitive types, type declarations, and basic type checking mechanisms.",
            "dependencies": [],
            "details": "Implement primitive types (string, number, boolean), type declarations syntax, type annotations, and basic type checking mechanisms. Create the TypeChecker class that will interface with the parser. Develop unit tests for each primitive type and basic type operations. Integration points: Receive AST from parser and attach type information to nodes.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Healthcare-Specific Type Definitions",
            "description": "Define and implement healthcare domain-specific types such as PatientID, MedicalRecord, Diagnosis, and related type traits.",
            "dependencies": [
              1
            ],
            "details": "Create healthcare-specific types (PatientID, MedicalRecord, Diagnosis, Medication, LabResult, etc.). Implement type traits for healthcare data (Identifiable, Timestamped, Auditable). Develop validation rules for each healthcare type. Test with realistic healthcare data examples. Integration points: Extend the type registry from subtask 1 with healthcare types.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Type Checking and Inference Implementation",
            "description": "Implement advanced type checking and type inference algorithms for healthcare data operations and transformations.",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement type inference for variable declarations and expressions. Create type checking for healthcare-specific operations (e.g., patient record merging, medication interactions). Develop error reporting for type mismatches with healthcare context. Test with complex healthcare workflows. Integration points: Hook type inference into expression evaluation in the parser.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Patient Data Safety Guarantees",
            "description": "Implement safety guarantees for patient data handling including privacy annotations, access control types, and data flow analysis.",
            "dependencies": [
              2,
              3
            ],
            "details": "Implement privacy annotation types (PHI, Anonymized, Authorized). Create access control type checking for patient data. Develop data flow analysis to track sensitive information. Implement HIPAA compliance type checks. Test with privacy violation scenarios. Integration points: Integrate with error reporting system and provide safety verification API for the runtime.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 3,
        "title": "Build LLVM Backend Integration for Compiler",
        "description": "Implement LLVM backend integration for efficient code generation with support for WebAssembly and initial RISC-V targets.",
        "details": "Integrate LLVM (version 15.0+) as the backend for the Medi compiler. Implement code generation from Medi AST to LLVM IR. Add support for WebAssembly target for browser deployments and initial RISC-V (RV32) support for medical IoT devices. Implement a basic optimization pipeline focused on healthcare workloads.\n\nKey components:\n1. AST to LLVM IR translation\n2. Target-specific code generation (x86-64, WebAssembly, RISC-V)\n3. Basic optimization passes for healthcare workloads\n4. Integration with the Medi type system\n\nPseudo-code for LLVM integration:\n```rust\nstruct LLVMContext { /* ... */ }\nstruct IRBuilder { /* ... */ }\n\nfn generate_llvm_ir(ast: &AST, context: &LLVMContext) -> Result<Module, CodeGenError> {\n  let builder = IRBuilder::new(context);\n  // Translate AST to LLVM IR\n  // Handle healthcare-specific constructs\n}\n\nfn optimize_module(module: &Module, level: OptLevel) -> Result<Module, OptError> {\n  // Apply optimization passes\n  // Healthcare-specific optimizations\n}\n\nfn generate_target_code(module: &Module, target: Target) -> Result<Vec<u8>, CodeGenError> {\n  // Generate machine code for the specified target\n  // Support x86-64, WebAssembly, RISC-V\n}\n```",
        "testStrategy": "Create integration tests for code generation with LLVM. Test compilation of Medi code to different targets (x86-64, WebAssembly, RISC-V). Benchmark generated code performance against the 2x C++ performance target. Test optimization passes with healthcare-specific workloads. Verify correct execution of compiled code across platforms.",
        "priority": "high",
        "dependencies": [
          1,
          2
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "LLVM Setup and Environment Configuration",
            "description": "Set up LLVM infrastructure and configure the build environment for backend integration",
            "dependencies": [],
            "details": "Install LLVM development packages (version 15.0+), configure CMake build system to link against LLVM libraries, set up header includes for LLVM API access, create wrapper classes for LLVM context, module, and builder objects, and establish the basic pipeline architecture for code generation",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "AST to LLVM IR Translation",
            "description": "Implement the translation layer from AST nodes to LLVM IR instructions",
            "dependencies": [
              1
            ],
            "details": "Create visitor pattern for AST traversal, implement IR generation for expressions (arithmetic, logical, comparison), handle variable declarations and assignments, implement control flow structures (if/else, loops, functions), manage memory allocations, and ensure proper scope handling for variables",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Target-Specific Code Generation: x86-64",
            "description": "Implement backend code generation for x86-64 target",
            "dependencies": [
              2
            ],
            "details": "Configure LLVM target machine for x86-64, implement x86-specific intrinsics and optimizations, handle System V ABI calling conventions, manage register allocation strategies, and ensure correct data layout and alignment for x86-64.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Optimization Pipeline Integration",
            "description": "Implement LLVM optimization passes tailored for healthcare workloads",
            "dependencies": [
              2,
              3
            ],
            "details": "Configure optimization pipeline with appropriate pass manager, implement function-level and module-level optimization passes, add healthcare-specific optimizations for numerical stability and precision, implement vectorization for SIMD operations, add memory access pattern optimizations, and create debug/release optimization profiles",
            "status": "pending"
          },
          {
            "id": 5,
            "title": "Type System Integration",
            "description": "Integrate the language's type system with LLVM's type representation",
            "dependencies": [
              2
            ],
            "details": "Map language primitive types to LLVM types, implement struct and array type representations, handle function types and signatures, implement generic type specialization for LLVM, manage ABI-compliant data layout, and ensure proper type conversions and promotions",
            "status": "pending"
          },
          {
            "id": 6,
            "title": "Testing Framework for Backend Validation",
            "description": "Develop comprehensive testing infrastructure for the LLVM backend",
            "dependencies": [
              1,
              2,
              3,
              4,
              5
            ],
            "details": "Create unit tests for IR generation, implement integration tests for end-to-end compilation, develop performance benchmarks for optimization evaluation, add regression tests for known edge cases, implement cross-platform validation tests, and create automated CI/CD pipeline for backend testing",
            "status": "pending"
          },
          {
            "id": 7,
            "title": "WebAssembly Target Implementation",
            "description": "Implement WebAssembly (wasm32-wasi) target for browser and server-side environments",
            "dependencies": [
              2
            ],
            "details": "Configure wasm32-wasi target triple, ensure correct memory model and calling conventions, implement any required intrinsics/shims, and integrate with toolchain for emitting .wasm modules. Provide example that runs in a minimal WASI runtime or browser (if applicable).",
            "status": "pending"
          },
          {
            "id": 8,
            "title": "RISC-V RV32 Codegen Path",
            "description": "Implement initial RISC-V RV32 code generation path for medical IoT devices",
            "dependencies": [
              2
            ],
            "details": "Configure riscv32 target triple, implement ABI/calling convention support, validate data layout and alignment, and ensure emitted code runs on a reference RV32 emulator or dev board. Provide minimal examples and measure footprint to meet edge constraints.",
            "status": "pending"
          },
          {
            "id": 9,
            "title": "CI Matrix for Targets",
            "description": "Add CI jobs to build and test x86-64, WebAssembly, and RISC-V RV32 targets",
            "dependencies": [
              3,
              7,
              8
            ],
            "details": "Create CI matrix (Linux) to validate IR, codegen, and smoke tests for x86-64, wasm32-wasi, and riscv32. Upload artifacts for inspection and gate merges on target build success.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 4,
        "title": "Implement Memory Management and Runtime System",
        "description": "Develop a memory management system with Rust-like borrow checking and a runtime system supporting multi-threading for healthcare workloads.",
        "details": "Implement a memory management system with Rust-like borrow checking for memory safety and concurrency. Create a runtime system that supports multi-threading for critical healthcare workloads and provides healthcare I/O primitives for standards-based data integration. Ensure the runtime has a small footprint for edge device deployments.\n\nKey components:\n1. Safe zone with basic garbage collection\n2. Simplified real-time zone for IoT prototypes\n3. Borrow checker for memory safety\n4. Task-based parallelism with channel-based message passing\n5. Error handling with Result type\n\nPseudo-code for memory management and runtime:\n```rust\nstruct BorrowChecker { /* ... */ }\nstruct GarbageCollector { /* ... */ }\nstruct Task { /* ... */ }\nstruct Channel<T> { /* ... */ }\n\nfn check_borrows(ast: &AST) -> Result<(), BorrowError> {\n  // Implement borrow checking logic\n}\n\nfn spawn_task(function: Fn(), priority: Priority) -> Task {\n  // Create and schedule a new task\n}\n\nfn create_channel<T>() -> (Sender<T>, Receiver<T>) {\n  // Create a message-passing channel\n}\n\nfn collect_garbage() {\n  // Perform garbage collection in the safe zone\n}\n```",
        "testStrategy": "Create unit tests for memory management components. Test borrow checking with various ownership patterns. Test multi-threading with healthcare workloads. Measure memory footprint on target devices. Test error handling with various error scenarios. Verify thread safety in concurrent healthcare data processing scenarios.",
        "priority": "medium",
        "dependencies": [
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Borrow Checker System",
            "description": "Design and implement a Rust-like borrow checker for static memory safety verification at compile time",
            "dependencies": [],
            "details": "Implement ownership rules, lifetime tracking, and reference validation. Create an abstract syntax tree (AST) analyzer to verify borrowing rules. Develop compile-time checks for mutable/immutable borrows. Test with comprehensive test suite covering edge cases like nested borrows and partial borrows. Performance requirement: Static analysis should complete within 100ms for files under 10,000 lines of code.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Develop Garbage Collection for Safe Zone",
            "description": "Implement a garbage collection system for the safe memory zone that provides automatic memory management",
            "dependencies": [
              1
            ],
            "details": "Create a mark-and-sweep collector with generational optimization. Implement weak references and finalization callbacks. Develop tunable GC parameters for different workloads. Test with memory-intensive benchmarks and leak detection tools. Performance requirement: GC pauses under 10ms for heaps up to 100MB, with throughput impact less than 10%.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Design Real-Time Zone for IoT Applications",
            "description": "Create a specialized memory management zone for real-time IoT applications with deterministic behavior",
            "dependencies": [
              1
            ],
            "details": "Implement region-based memory allocation with compile-time size determination. Create a pool allocator for fixed-size objects. Develop static analysis tools to verify real-time constraints. Test with simulated IoT workloads and timing verification. Performance requirement: Allocation/deallocation operations must complete in constant time (O(1)) with maximum latency of 50μs.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Implement Task-Based Parallelism Framework",
            "description": "Develop a task-based parallelism system with work-stealing scheduler and memory isolation",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Create a work-stealing scheduler with priority support. Implement memory isolation between tasks. Develop channel-based message passing for inter-task communication. Test with parallel algorithms and concurrency stress tests. Performance requirement: Scaling efficiency of at least 80% up to 16 cores with task creation overhead under 5μs.",
            "status": "pending"
          },
          {
            "id": 5,
            "title": "Implement Comprehensive Error Handling System",
            "description": "Design and implement an error handling system that integrates with memory management and provides detailed diagnostics",
            "dependencies": [
              1,
              2,
              3,
              4
            ],
            "details": "Create a typed error system with propagation mechanisms. Implement memory safety violation reporting with source code context. Develop runtime error recovery strategies. Test with fault injection and recovery scenarios. Performance requirement: Error handling overhead should not exceed 5% of total execution time, with detailed diagnostics generation under 1ms.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 5,
        "title": "Develop Core Standard Library Modules",
        "description": "Implement essential standard library modules including medi.data, medi.stats, medi.compliance, and medi.ai.",
        "details": "Develop the core standard library modules for Medi:\n\n1. `medi.data`:\n   - FHIR resource definitions and parsers\n   - Native representation of healthcare data structures\n   - Querying capabilities for patient records\n   - Data validation against healthcare standards\n\n2. `medi.stats`:\n   - Basic statistical functions for clinical data\n   - Descriptive statistics for patient cohorts\n   - Simple hypothesis testing (t-tests, etc.)\n   - Foundations for clinical trial analysis\n\n3. `medi.compliance`:\n   - HIPAA compliance checking primitives\n   - Data anonymization utilities\n   - Audit trail generation\n   - Basic regulatory reporting templates\n\n4. `medi.ai`:\n   - Interfaces for ML model integration\n   - Simple risk prediction utilities\n   - Foundation for federated learning\n\nPseudo-code for standard library implementation:\n```rust\n// medi.data module\nstruct FHIRResource { /* ... */ }\nstruct FHIRPatient : FHIRResource { /* ... */ }\nstruct FHIRObservation : FHIRResource { /* ... */ }\n\nfn fhir_query(resource_type: &str) -> QueryBuilder { /* ... */ }\nfn validate_fhir(resource: &FHIRResource) -> Result<(), ValidationError> { /* ... */ }\n\n// medi.stats module\nfn mean(values: &[f64]) -> f64 { /* ... */ }\nfn t_test(group1: &[f64], group2: &[f64]) -> TTestResult { /* ... */ }\n\n// medi.compliance module\nfn check_hipaa_compliance(data: &Data, rules: &[ComplianceRule]) -> ComplianceResult { /* ... */ }\nfn anonymize(data: &Data, method: AnonymizationMethod) -> AnonymizedData { /* ... */ }\n\n// medi.ai module\nfn load_model(path: &str) -> Model { /* ... */ }\nfn predict_risk(patient: &FHIRPatient, model: &Model) -> RiskScore { /* ... */ }\n```",
        "testStrategy": "Create comprehensive unit tests for each standard library module. Test FHIR parsing and querying with real and synthetic healthcare data. Validate statistical functions against known results. Test compliance checking against HIPAA requirements. Benchmark AI model integration. Create integration tests that use multiple modules together to solve healthcare problems from the key use cases in the PRD.",
        "priority": "high",
        "dependencies": [
          2,
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Develop medi.data Module",
            "description": "Create the medi.data module for standardized healthcare data structures and operations",
            "dependencies": [],
            "details": "Implement core data structures for patient records, medical events, and clinical observations. Include functions for data validation, sanitization, and transformation. Create parsers for common healthcare formats (FHIR, HL7, DICOM). Develop serialization/deserialization utilities. Implement secure storage abstractions with encryption. Add comprehensive documentation with examples. Test with real and synthetic healthcare datasets, focusing on data integrity, performance with large datasets, and compliance with standards.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Develop medi.stats Module",
            "description": "Create the medi.stats module for healthcare-specific statistical analysis",
            "dependencies": [
              1
            ],
            "details": "Implement statistical functions for clinical trials, epidemiology, and outcomes research. Create visualization tools for medical data. Develop risk scoring and predictive modeling utilities. Add functions for population health analysis. Implement quality metrics calculations (HEDIS, STAR). Create time-series analysis for patient monitoring data. Test with benchmark datasets, validate against established statistical packages, and ensure numerical stability across diverse datasets.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Develop medi.compliance Module",
            "description": "Create the medi.compliance module for healthcare regulatory requirements",
            "dependencies": [
              1
            ],
            "details": "Implement HIPAA compliance validation tools. Create audit logging mechanisms. Develop de-identification and anonymization utilities. Add consent management functions. Implement data retention policy enforcement. Create regulatory reporting templates (FDA, CMS). Develop validation for international standards (GDPR, PIPEDA). Test with compliance checklists, penetration testing for security features, and validation against regulatory requirements documentation.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Develop medi.ai Module",
            "description": "Create the medi.ai module for healthcare-specific AI and ML capabilities",
            "dependencies": [
              1,
              2
            ],
            "details": "Implement medical image processing utilities. Create NLP functions for clinical text. Develop predictive modeling for disease progression. Add diagnostic decision support tools. Implement patient risk stratification. Create model validation tools specific to healthcare. Develop explainability functions for clinical AI. Test with benchmark medical datasets, validate against clinical ground truth, and perform bias testing across diverse patient populations.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 6,
        "title": "Implement Privacy and Compliance Checking",
        "description": "Develop a privacy/compliance checking stage for HIPAA/GDPR rules in the compiler pipeline.",
        "details": "Implement a privacy and compliance checking stage in the compiler pipeline that verifies code against HIPAA and GDPR rules. This should include static analysis to detect potential privacy violations and ensure proper handling of protected health information (PHI).\n\nKey components:\n1. Static analysis for PHI data flows\n2. Detection of unprotected PHI usage\n3. Verification of proper anonymization\n4. Checking for compliance with the `regulate` construct\n5. Integration with the type system's PrivacyProtected trait\n\nPseudo-code for compliance checking:\n```rust\nstruct ComplianceChecker { rules: Vec<ComplianceRule> }\nstruct ComplianceViolation { location: SourceLocation, rule: ComplianceRule, message: String }\n\nfn check_compliance(ast: &AST, rules: &[ComplianceRule]) -> Vec<ComplianceViolation> {\n  let mut violations = Vec::new();\n  // Analyze AST for compliance violations\n  // Check data flows for PHI\n  // Verify proper use of regulate blocks\n  // Ensure anonymization before data export\n  violations\n}\n\nfn verify_regulate_block(regulate_node: &AST) -> Vec<ComplianceViolation> {\n  // Verify that regulate blocks properly protect data\n  // Check that standards are correctly specified\n  // Ensure all required checks are included\n}\n```",
        "testStrategy": "Create unit tests with various compliance scenarios. Test with code that violates HIPAA/GDPR rules to verify detection. Test with compliant code to ensure no false positives. Create test cases for each compliance rule. Validate against the HIPAA Safe Harbor Method requirements. Test the `regulate` construct with various configurations.",
        "priority": "medium",
        "dependencies": [
          2,
          5
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "PHI Data Flow Analysis",
            "description": "Implement static analysis to track the flow of Protected Health Information (PHI) throughout the codebase",
            "dependencies": [],
            "details": "Develop a data flow analysis tool that identifies PHI data sources, tracks variable assignments, function calls, and data persistence operations. Create a graph representation of PHI data movement. Implement detection for common PHI types (names, addresses, medical record numbers, etc.). Testing approach: Create test cases with known PHI flows and verify detection accuracy. Regulatory requirements: Document HIPAA identifiers (18 types) and GDPR personal data categories being tracked.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Detection of Unprotected PHI Usage",
            "description": "Build detection mechanisms for identifying instances where PHI is used without proper protection measures",
            "dependencies": [
              1
            ],
            "details": "Using the data flow graph from subtask 1, implement checks for: PHI transmitted without encryption, PHI stored without access controls, PHI logged to console/files, PHI exposed in UI without masking. Create severity classification for violations. Testing approach: Develop test suite with intentional violations and verify detection. Regulatory requirements: Map each detection rule to specific HIPAA/GDPR requirements for documentation.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Verification of Proper Anonymization",
            "description": "Implement verification mechanisms to ensure PHI is properly anonymized when required",
            "dependencies": [
              1,
              2
            ],
            "details": "Develop checks for proper anonymization techniques: k-anonymity, differential privacy, pseudonymization. Create validators for common anonymization functions. Implement detection of re-identification risks. Testing approach: Test with various anonymization approaches and attempt re-identification attacks. Regulatory requirements: Document compliance with HIPAA Safe Harbor and GDPR Article 4 anonymization standards.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Integration with Regulate Construct",
            "description": "Integrate privacy and compliance checking with the regulate construct to enforce policies",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Develop API for the regulate construct to access compliance checking results. Implement policy enforcement mechanisms based on detected violations. Create reporting functionality for compliance status. Build remediation suggestions for detected issues. Testing approach: Test integration points with mock regulate constructs and verify policy enforcement. Regulatory requirements: Ensure integration supports documentation generation for compliance audits.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 7,
        "title": "Build Command-Line Interface and REPL",
        "description": "Develop the medic compiler CLI with basic options, a REPL for interactive development, and package manager foundation.",
        "details": "Implement a command-line interface (CLI) for the Medi compiler (`medic`) with basic compilation options. Create a Read-Eval-Print Loop (REPL) for interactive development. Lay the foundation for a package manager (`medipack`). Implement a basic documentation generator.\n\nNote: This umbrella task is superseded by Tasks 12–15 which track each deliverable explicitly.\n\nKey components:\n1. Compiler CLI with options for target selection, optimization level, etc.\n2. Interactive REPL with healthcare data visualization\n3. Package manager foundation with dependency resolution\n4. Documentation generator for Medi code\n\nPseudo-code for CLI implementation:\n```rust\nstruct CompilerOptions {\n  input_file: String,\n  output_file: Option<String>,\n  target: Target,\n  opt_level: OptLevel,\n  // Other options\n}\n\nfn parse_cli_args() -> CompilerOptions { /* ... */ }\n\nfn compile_file(options: &CompilerOptions) -> Result<(), CompileError> { /* ... */ }\n\nfn run_repl() -> Result<(), ReplError> {\n  loop {\n    // Read input\n    // Parse and evaluate\n    // Print result\n    // Handle special commands\n  }\n}\n\nfn generate_docs(input_files: &[String], output_dir: &str) -> Result<(), DocError> { /* ... */ }\n```",
        "testStrategy": "Create integration tests for the CLI with various command-line options. Test the REPL with interactive sessions including healthcare data analysis. Test documentation generation with sample Medi code. Verify correct handling of compiler errors and warnings. Test package management functionality with mock packages.",
        "priority": "medium",
        "dependencies": [
          3,
          4,
          5
        ],
        "status": "deferred",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Compiler Command-Line Interface",
            "description": "Develop a robust CLI for the compiler that handles command-line arguments, file processing, and execution options",
            "dependencies": [],
            "details": "Create a CLI that supports: 1) File input/output options, 2) Compilation flags and optimization levels, 3) Error reporting with clear messages and line numbers, 4) Verbose mode for debugging, 5) Help documentation, 6) Version information. Integrate with the compiler pipeline to process source files. Implement proper exit codes for success/failure states. Design for extensibility to add new options in future releases. Ensure cross-platform compatibility.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Develop REPL with Healthcare Data Visualization",
            "description": "Create an interactive Read-Eval-Print Loop with specialized features for healthcare data visualization and exploration",
            "dependencies": [
              1
            ],
            "details": "Build a REPL environment that: 1) Provides immediate feedback for code snippets, 2) Supports multi-line input with syntax highlighting, 3) Implements healthcare-specific visualization commands for patient data, trends, and metrics, 4) Includes data import/export capabilities for common healthcare formats, 5) Offers context-aware autocompletion, 6) Maintains session history. Ensure visualizations are accessible and clinically relevant. Integrate with the compiler's interpreter mode for real-time execution.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Create Documentation Generator",
            "description": "Implement a tool to automatically generate documentation from source code and integrate it with the CLI",
            "dependencies": [
              1
            ],
            "details": "Develop a documentation generator that: 1) Extracts documentation comments from source code, 2) Generates structured documentation in multiple formats (HTML, PDF, Markdown), 3) Creates cross-references between related components, 4) Includes examples and usage patterns, 5) Documents healthcare-specific functions with clinical context. Add CLI commands to generate documentation on demand. Implement templates for consistent documentation styling. Include validation to ensure documentation completeness and accuracy.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 8,
        "title": "Develop Basic IDE with Visual Analytics",
        "description": "Create a basic IDE with visual analytics capabilities, syntax highlighting, and code completion for Medi.",
        "details": "Develop a basic Integrated Development Environment (IDE) for Medi with visual analytics capabilities, support for `.medi` file recognition, syntax highlighting, and basic code completion. Create a prototype of the visual programming interface.\n\nKey components:\n1. Text editor with syntax highlighting for Medi\n2. Code completion using the type system\n3. Visual analytics for healthcare data\n4. Integration with the medic compiler\n5. Prototype visual programming interface\n\nImplementation approach:\n1. Build on existing open-source editor frameworks\n2. Implement Medi language server protocol\n3. Create visualization components for healthcare data\n4. Design visual programming blocks for healthcare operations\n\nPseudo-code for IDE components:\n```typescript\nclass MediLanguageServer {\n  // Implement Language Server Protocol\n  onCompletion(document: TextDocument, position: Position): CompletionItem[] { /* ... */ }\n  onHover(document: TextDocument, position: Position): Hover { /* ... */ }\n  // Other LSP methods\n}\n\nclass HealthcareVisualizer {\n  renderPatientData(patient: FHIRPatient): SVGElement { /* ... */ }\n  renderStatistics(data: StatisticalResult): SVGElement { /* ... */ }\n  // Other visualization methods\n}\n\nclass VisualProgrammingInterface {\n  createBlock(blockType: string): Block { /* ... */ }\n  connectBlocks(source: Block, target: Block): Connection { /* ... */ }\n  generateCode(): string { /* ... */ }\n  // Other visual programming methods\n}\n```",
        "testStrategy": "Create UI tests for the IDE components. Test syntax highlighting with various Medi code samples. Test code completion with healthcare-specific constructs. Verify visual analytics with sample healthcare data. Test integration with the compiler. Conduct usability testing with target users (clinicians, researchers, developers).",
        "priority": "low",
        "dependencies": [
          1,
          2,
          5
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Text Editor with Syntax Highlighting",
            "description": "Develop a text editor component with syntax highlighting capabilities for multiple programming languages",
            "dependencies": [],
            "details": "Implementation details: Use Monaco Editor or CodeMirror as the base editor component. Implement syntax highlighting for Python, JavaScript, and SQL at minimum. Add line numbering, bracket matching, and code folding features. User experience requirements: Ensure responsive editing with minimal lag, customizable themes (light/dark), and keyboard shortcuts for common operations. Integration points: Create a modular architecture that allows other components to access and modify editor content programmatically.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Develop Code Completion Using Type System",
            "description": "Implement intelligent code completion functionality leveraging the language's type system",
            "dependencies": [
              1
            ],
            "details": "Implementation details: Integrate with Language Server Protocol (LSP) for language-aware code completion. Implement type inference for dynamically typed languages. Create a suggestion display component that shows parameter hints and documentation. User experience requirements: Low-latency suggestions (under 200ms), filtering capabilities, and keyboard navigation for completion items. Integration points: Connect with the text editor component, access to project files for context-aware completion, and hooks for custom completion providers.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Create Visual Analytics for Healthcare Data",
            "description": "Develop visualization components specifically designed for healthcare data analysis",
            "dependencies": [
              1
            ],
            "details": "Implementation details: Build reusable chart components (line charts, scatter plots, heatmaps) optimized for healthcare metrics. Implement data preprocessing utilities for common healthcare data formats (FHIR, HL7). Create interactive dashboards with filtering capabilities. User experience requirements: Accessible visualizations following healthcare UI guidelines, tooltips with detailed information, and export functionality. Integration points: Data connectors to common healthcare databases, integration with the editor for custom visualization code, and APIs for extending with new visualization types.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Design Prototype Visual Programming Interface",
            "description": "Create a prototype interface for visual programming that integrates with the text-based IDE",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Implementation details: Develop a node-based programming canvas using a library like D3.js or React Flow. Implement drag-and-drop functionality for code blocks and data sources. Create a bidirectional sync between visual representation and text code. User experience requirements: Intuitive connection mechanism between nodes, undo/redo functionality, and visual feedback for execution flow. Integration points: Conversion between visual representation and text code, integration with code completion system, and hooks into the healthcare visualization components.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 9,
        "title": "Implement Example Use Cases",
        "description": "Develop working examples for the key use cases: Clinical Data Exploration, Basic Regulatory Compliance, Simple Statistical Analysis, and Synthetic Data Testing.",
        "details": "Implement working examples for the four key use cases specified in the PRD:\n\n1. Clinical Data Exploration:\n```medi\nlet patients = fhir_query(\"Patient\")\n    .filter(p => p.age > 65 && p.condition(\"diabetes\"))\n    .limit(100);\n\nlet avg_a1c = patients.observation(\"hba1c\").mean();\nprintln!(\"Average HbA1c: {:.1}%\", avg_a1c);\n```\n\n2. Basic Regulatory Compliance:\n```medi\nregulate {\n  standard: \"HIPAA\",\n  data: patient_records,\n  checks: [\"de_identification\", \"minimum_necessary\"]\n};\n\nlet analysis = analyze(patient_records);\n```\n\n3. Simple Statistical Analysis:\n```medi\nlet trial_data = load_csv(\"trial_results.csv\");\nlet treatment_group = trial_data.filter(p => p.group == \"treatment\");\nlet control_group = trial_data.filter(p => p.group == \"control\");\n\nlet t_test = stats.t_test(treatment_group.outcome, control_group.outcome);\nprintln!(\"P-value: {:.4}\", t_test.p_value);\n```\n\n4. Synthetic Data Testing:\n```medi\nlet synthetic_patients = generate_synthetic_patients(100, {\n  demographics: \"realistic\",\n  conditions: [\"diabetes\", \"hypertension\"],\n  observations: [\"glucose\", \"blood_pressure\"]\n});\n\nlet analysis = run_risk_model(synthetic_patients);\n```\n\nEnsure that all examples work end-to-end with the implemented compiler and standard library. Create sample datasets for testing these examples.",
        "testStrategy": "Create end-to-end tests for each use case. Test with real and synthetic healthcare data. Verify correct output for each example. Measure performance against the targets specified in the PRD. Test integration with the standard library modules. Ensure compliance checking works correctly in the regulatory example.",
        "priority": "medium",
        "dependencies": [
          5,
          6
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Implement Clinical Data Exploration Use Case",
            "description": "Develop a comprehensive example demonstrating how to explore and analyze clinical datasets using the language's data manipulation features.",
            "dependencies": [],
            "details": "Create a step-by-step tutorial showing how to load clinical data (FHIR or similar format), filter patients by criteria, extract relevant medical information, and visualize key metrics. Include code samples for common operations like cohort selection, timeline visualization, and basic patient statistics. Use realistic (but anonymized) sample data and document all functions used.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Implement Basic Regulatory Compliance Use Case",
            "description": "Create an example showing how the language handles HIPAA and other healthcare compliance requirements in code.",
            "dependencies": [
              1
            ],
            "details": "Develop a tutorial demonstrating data anonymization techniques, audit logging, access control implementation, and secure data storage patterns. Include code examples for de-identification functions, consent management, and automated compliance checking. Document how the language's features specifically address regulatory requirements with concrete implementation examples.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Implement Simple Statistical Analysis Use Case",
            "description": "Build an example showcasing statistical analysis capabilities for healthcare data using the language's built-in functions.",
            "dependencies": [
              1
            ],
            "details": "Create a comprehensive example that demonstrates descriptive statistics, hypothesis testing, correlation analysis, and basic predictive modeling on healthcare data. Include code for analyzing treatment outcomes, identifying risk factors, and generating statistical reports. Provide sample datasets and expected outputs with interpretations of the results.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Implement Synthetic Data Testing Use Case",
            "description": "Develop an example showing how to generate and validate synthetic healthcare data for testing applications.",
            "dependencies": [
              1,
              2,
              3
            ],
            "details": "Create a tutorial demonstrating how to generate realistic synthetic patient records, medical events, and longitudinal data. Include code for data validation, statistical similarity testing with real data, and integration testing scenarios. Document methods for controlling data characteristics, ensuring clinical plausibility, and scaling data generation for different testing needs.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 10,
        "title": "Create Documentation and Performance Benchmarks",
        "description": "Develop comprehensive documentation for all implemented features and create performance benchmarks against Python/R for healthcare tasks.",
        "details": "Create comprehensive documentation covering all implemented features of the Medi language. Develop performance benchmarks comparing Medi against Python and R for common healthcare tasks. Document the language specification, standard library API, and development tools.\n\nDocumentation components:\n1. Language specification\n2. Standard library API reference\n3. Compiler and tools usage guide\n4. Tutorial for healthcare developers\n5. Example code repository\n\nBenchmarking components:\n1. Performance comparison with Python/R for statistical analysis\n2. Memory usage benchmarks\n3. Compilation speed measurements\n4. Healthcare-specific workload benchmarks\n\nImplementation approach:\n1. Use a documentation generator for API references\n2. Create markdown documentation for guides and tutorials\n3. Implement benchmark suite with comparable implementations in Python/R\n4. Measure and report performance metrics\n\nPseudo-code for benchmarking:\n```rust\nstruct BenchmarkResult {\n  language: String,\n  task: String,\n  execution_time_ms: f64,\n  memory_usage_mb: f64,\n}\n\nfn run_benchmarks() -> Vec<BenchmarkResult> {\n  let mut results = Vec::new();\n  // Run Medi benchmarks\n  // Run equivalent Python benchmarks\n  // Run equivalent R benchmarks\n  // Collect and compare results\n  results\n}\n\nfn generate_benchmark_report(results: &[BenchmarkResult], output_file: &str) { /* ... */ }\n```",
        "testStrategy": "Verify documentation accuracy with code examples. Test documentation generator with all standard library modules. Run benchmarks on different hardware configurations. Compare benchmark results against the performance targets in the PRD. Ensure documentation covers all implemented features. Test tutorials with users unfamiliar with Medi.",
        "priority": "medium",
        "dependencies": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Language and API Documentation",
            "description": "Create comprehensive documentation for the Medi language syntax, features, and standard library APIs",
            "dependencies": [],
            "details": "Implement detailed documentation covering: language syntax, control structures, data types, standard library functions, error handling, and development tools. Include code examples for each feature. Documentation should be organized in a hierarchical structure with clear navigation. Quality criteria: completeness (all features documented), clarity (understandable to beginners), accuracy (no errors), and usefulness (practical examples). Deliver as HTML/Markdown files with proper formatting, syntax highlighting, and searchable index.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Performance Benchmarking Suite",
            "description": "Develop a comprehensive suite of performance benchmarks for the Medi language",
            "dependencies": [
              1
            ],
            "details": "Create benchmarks measuring: computation speed, memory usage, I/O performance, concurrency handling, and statistical analysis operations. Implement automated testing framework that runs benchmarks in controlled environments with consistent hardware/software configurations. Include small, medium, and large dataset tests. Quality criteria: reproducibility, statistical validity (multiple runs with variance analysis), and comprehensive coverage of language features. Deliver as executable test suite with configuration files and logging capabilities.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Comparative Analysis with Python/R",
            "description": "Conduct detailed performance and feature comparison between Medi and Python/R",
            "dependencies": [
              2
            ],
            "details": "Perform side-by-side comparison of Medi vs Python vs R across: execution speed for common data science tasks, memory efficiency, code readability, feature completeness, and ecosystem integration. Create equivalent implementations of benchmark tasks in all three languages. Analyze strengths/weaknesses of each approach. Quality criteria: fairness (unbiased comparison), thoroughness (covers major use cases), and actionable insights. Deliver as detailed report with data visualizations, statistical analysis of performance differences, and recommendations for Medi improvement areas.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 11,
        "title": "Implement Python FFI Prototype",
        "description": "Create a Python FFI prototype to enable basic interoperability between Medi and Python, as specified in PRD Phase 1 (Platform Support: Python FFI prototype).",
        "details": "Implement an initial Foreign Function Interface (FFI) between Medi (Rust) and Python to support: 1) Calling selected Medi-compiled functions from Python, 2) Invoking Python libraries from Medi where appropriate via a safe boundary. Use Rust's PyO3/maturin toolchain to expose a minimal set of APIs for demonstration.\n\nScope (Phase 1 prototype):\n- Build a small Rust crate that wraps core Medi functionality and exposes it as a Python module (e.g., `pymedi`).\n- Support passing simple data types and a basic FHIR-like structure for demo purposes.\n- Provide examples: calling a Medi `mean` function and a simple `fhir_query`-like stub from Python.\n- Document build/setup using maturin and Python virtualenv.\n\nOut of scope (defer to Phase 2+):\n- Full bidirectional interop and complex zero-copy buffers\n- Rich error mapping and async interop\n\nDeliverables:\n- `pymedi` prototype wheel build instructions\n- Example Python scripts demonstrating calls into Medi\n- Minimal CI job to build the wheel on Linux\n",
        "testStrategy": "Create Python-based tests that import the generated `pymedi` module and exercise: 1) Basic function calls with primitives, 2) Passing a small dict representing a FHIR resource, 3) Error handling paths. Verify that the build works on Linux with Python 3.10+. Benchmark overhead compared to native Medi for a trivial function.",
        "priority": "medium",
        "dependencies": [
          1,
          3,
          5
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Set up PyO3/Maturin Build Pipeline",
            "description": "Configure Rust crate with PyO3 and maturin for building a Python wheel",
            "dependencies": [],
            "details": "Add PyO3 and maturin dependencies, configure `Cargo.toml` for a `cdylib` target, and set up a basic GitHub Actions or local script to build the wheel. Document Python environment setup and build steps.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Expose Minimal Medi APIs to Python",
            "description": "Expose a small set of Medi functions (e.g., mean function from medi.stats and a fhir_query stub) as Python-callable functions",
            "dependencies": [
              1
            ],
            "details": "Implement PyO3 wrappers for at least two functions. Ensure type conversions for primitives and a small dict payload. Provide example Python scripts.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Python-side Tests and Examples",
            "description": "Create unit tests and example scripts that import and use the `pymedi` module",
            "dependencies": [
              1,
              2
            ],
            "details": "Write pytest or simple assert-based tests to validate function calls and error handling. Provide a README with usage instructions and expected outputs.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 12,
        "title": "Implement CLI Compiler (medic)",
        "description": "Create the command-line compiler with compile/run modes, target selection, and diagnostics.",
        "details": "Implement `medic` with: 1) compile to IR/obj/asm; 2) run mode; 3) flags: -o, --target (x86-64, wasm32-wasi, riscv32), --emit, --opt-level; 4) rich diagnostics with clinician-friendly messages; 5) help/version. Wire parser, type checker, and backend stages.",
        "testStrategy": "Snapshot tests for CLI help/usage; E2E compile-and-run smoke tests for sample programs across targets; diagnostics golden tests for typical errors.",
        "priority": "high",
        "dependencies": [
          1,
          2,
          3
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Arg Parsing and UX",
            "description": "Design CLI flags and UX, implement help/version and validation",
            "dependencies": [],
            "details": "Use a robust arg parser; ensure clear error messages and examples.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Driver Wiring",
            "description": "Connect parse -> typecheck -> codegen -> emit/run",
            "dependencies": [
              1
            ],
            "details": "Implement clean compile pipeline with proper exit codes.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Target Selection and Artifacts",
            "description": "Support x86-64, wasm32-wasi, and riscv32 outputs",
            "dependencies": [
              2
            ],
            "details": "Emit IR/obj/asm; integrate with Task 3 targets.",
            "status": "pending"
          },
          {
            "id": 4,
            "title": "Diagnostics Formatting",
            "description": "Clinician-friendly diagnostics with code frames",
            "dependencies": [],
            "details": "Pretty-print errors and warnings with suggestions.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 13,
        "title": "Implement REPL",
        "description": "Interactive shell for evaluating Medi expressions with clinician-friendly errors.",
        "details": "Line editing/history; multi-line input; incremental parsing/type checking; evaluation via runtime; pretty-print values and errors; session commands (load, vars, help).",
        "testStrategy": "Transcript-based tests of interactive sessions; unit tests for incremental compilation and error recovery.",
        "priority": "high",
        "dependencies": [
          1,
          2,
          4
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Input Loop & History",
            "description": "Implement readable prompt, history, and multi-line input",
            "dependencies": [],
            "details": "Add commands: :help, :load, :quit.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Incremental Compile",
            "description": "Incremental parse/typecheck of snippets",
            "dependencies": [
              1
            ],
            "details": "Preserve state across inputs for names/types.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Eval & Display",
            "description": "Evaluate via runtime and pretty-print results/errors",
            "dependencies": [
              2
            ],
            "details": "Clinician-friendly formatting and summaries.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 14,
        "title": "Package Manager Foundation (medipack)",
        "description": "Initialize projects and build with a minimal manifest; stub dependency resolution for Phase 1.",
        "details": "Commands: medipack init (scaffold), medipack build (invoke medic); manifest medi.toml (name, version, deps placeholder). Prepare for future registry.",
        "testStrategy": "E2E tests for init/build; manifest parser validation; integration test with medic.",
        "priority": "medium",
        "dependencies": [
          1,
          12
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Manifest Design & Parser",
            "description": "Define medi.toml schema and parser",
            "dependencies": [],
            "details": "Fields: name, version, deps (stub).",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Project Init",
            "description": "Scaffold new project layout",
            "dependencies": [
              1
            ],
            "details": "Create src/main.medi, medi.toml, README.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "Build Integration",
            "description": "Invoke medic compile from medipack",
            "dependencies": [
              2
            ],
            "details": "Pipe flags and handle build artifacts.",
            "status": "pending"
          }
        ]
      },
      {
        "id": 15,
        "title": "Documentation Generator",
        "description": "Generate reference docs/examples from source and comments; integrate with CLI.",
        "details": "Extract doc comments; render Markdown/HTML; build example index; link to standard library APIs; CLI command to generate docs.",
        "testStrategy": "Golden-file snapshots of generated docs; example extraction and linking tests.",
        "priority": "medium",
        "dependencies": [
          1,
          5
        ],
        "status": "pending",
        "subtasks": [
          {
            "id": 1,
            "title": "Extractor",
            "description": "Parse source for doc comments and metadata",
            "dependencies": [],
            "details": "Support modules/functions/types.",
            "status": "pending"
          },
          {
            "id": 2,
            "title": "Renderer",
            "description": "Render Markdown/HTML with navigation",
            "dependencies": [
              1
            ],
            "details": "Support code fences and links.",
            "status": "pending"
          },
          {
            "id": 3,
            "title": "CLI Integration",
            "description": "Add medic subcommand to generate docs",
            "dependencies": [
              2
            ],
            "details": "medic docs --out ./docs",
            "status": "pending"
          }
        ]
      },
      {
        "id": 16,
        "title": "Implement Feature-Gated Pipeline Operator",
        "description": "Add support for a single-token pipeline operator '|>' in the Medi lexer, gated behind a Cargo feature flag to preserve backward compatibility.",
        "details": "Implement a feature-gated single-token pipeline operator '|>' across the medic_lexer module with the following steps:\n\n1. Add new token types:\n   - Add `LogosToken::PipeGreater` to the Logos token enum\n   - Add `TokenType::PipeGreater` to the token type enum\n\n2. Update token conversion:\n   - Modify `convert_logos_to_token()` to handle the new token type\n   - Ensure proper span information is preserved\n\n3. Enable recognition in lexer modules:\n   - Update `lexer/mod.rs` to recognize the new token\n   - Update `streaming_lexer.rs` to handle the token in streaming contexts\n   - Update `chunked_lexer.rs` to properly handle the token, including special handling for chunk boundaries where '|' and '>' might be split across chunks\n\n4. Add a new Cargo feature flag:\n   - Create a new feature flag (e.g., `pipeline-operator`) that is disabled by default\n   - Gate the single-token behavior behind this feature\n   - When the feature is disabled, the lexer should continue to recognize '|' and '>' as separate tokens (BitOr and Greater)\n   - When enabled, recognize '|>' as a single PipeGreater token\n\n5. Update documentation:\n   - Add the new token to the language specification in LANG_SPEC.md\n   - Document the feature flag in relevant README files\n   - Add usage examples showing both default and feature-enabled behavior\n\n6. Ensure backward compatibility:\n   - Verify that existing tests pass with the feature disabled\n   - Confirm that the lexer behavior is unchanged for existing code when the feature is off",
        "testStrategy": "1. Unit tests for token recognition:\n   - Test that '|>' is recognized as a single token when the feature is enabled\n   - Test that '|' and '>' are recognized as separate tokens when the feature is disabled\n   - Test edge cases like whitespace between '|' and '>'\n\n2. Chunked lexer tests:\n   - Test recognition when '|' and '>' are in the same chunk\n   - Test recognition when '|' is at the end of one chunk and '>' is at the beginning of the next\n   - Verify correct behavior with various chunk sizes\n\n3. Streaming lexer tests:\n   - Test streaming recognition of the pipeline operator\n   - Verify correct token boundaries in streaming mode\n\n4. Feature flag tests:\n   - Create test modules that conditionally compile based on the feature flag\n   - Verify both behaviors (single token vs. two tokens) with appropriate test cases\n\n5. Integration tests:\n   - Test the lexer in the context of the full parser\n   - Verify that expressions using the pipeline operator are correctly parsed\n\n6. Regression tests:\n   - Run the existing test suite with the feature disabled to ensure no regressions\n   - Create a comprehensive test suite that passes regardless of feature flag state",
        "status": "pending",
        "dependencies": [
          1
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "Clinician User Testing and Feedback Integration (Diagnostics)",
        "description": "Plan and conduct clinician user testing for diagnostic output; collect feedback; integrate improvements into severity mapping, wording, help text, and snippet visuals.",
        "details": "Acceptance Criteria:\n- Recruit 3–5 clinicians or clinician-adjacent users\n- Prepare test scripts with representative error scenarios and snippet outputs\n- Run moderated sessions (remote or in-person); capture notes and key observations\n- Aggregate feedback into an actionable report with prioritized recommendations\n- Create tracked issues/tasks for the top findings (e.g., severity tuning, messages, guidance)\n- Implement at least 3 high-impact improvements and corresponding tests\n- Update docs with a section informed by user findings (examples, guidance)\nDeliverables:\n- Test plan, session notes, and summary report\n- Issue list with priorities and owners\n- PRs implementing improvements and updated tests",
        "testStrategy": "User-research task. Verify via artifacts (plan, notes, report), created issues, and merged PRs with passing tests.",
        "priority": "medium",
        "dependencies": [
          5
        ],
        "status": "pending"
      }
    ],
    "metadata": {
      "created": "2025-08-23T01:27:51.072Z",
      "updated": "2025-08-24T00:59:34.814Z",
      "description": "Tasks for master context"
    }
  }
}